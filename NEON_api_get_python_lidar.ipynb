{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download some lidar data using the [NEON Data Portal API](http://data.neonscience.org/data-api)\n",
    "\n",
    "First we are going to import `requests` and `json` libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "SITECODE = \"SRER\" #the site code for Santa Rita Experimental Range\n",
    "PRODUCTCODE = \"DP1.30003.001\" #the product code for Discrete Return lidar\n",
    "SERVER = \"http://data.neonscience.org/api/v0/\" #the current server address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to track how big the files sizes are - in case there is a breakdown in the transfer.\n",
    "\n",
    "Here is a simple way to track the file size using some definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bytes(num):\n",
    "    \"\"\"\n",
    "    this function will convert bytes to MB.... GB... etc\n",
    "    \"\"\"\n",
    "    for x in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n",
    "        if num < 1024.0:\n",
    "            return \"%3.1f %s\" % (num, x)\n",
    "        num /= 1024.0\n",
    "\n",
    "def file_size(file_path):\n",
    "    \"\"\"\n",
    "    this function will return the file size\n",
    "    \"\"\"\n",
    "    if os.path.isfile(file_path):\n",
    "        file_info = os.stat(file_path)\n",
    "        return convert_bytes(file_info.st_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We query the server for the site location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_response = requests.get(SERVER + 'sites/' + SITECODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a JSON blob for viewing the data at this site:"
   ]
  },

   "source": [
    "site_response_json = site_response.json()\n",
    "print(json.dumps(site_response_json, indent=2)) #using json.dumps for formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We subset the data to look for the discrete lidar data by date using the product code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2017-08']\n"
     ]
    }
   ],
   "source": [
    "data_products = site_response_json['data']['dataProducts']\n",
    "\n",
    "#use a list comprehension here if you're feeling fancy\n",
    "for data_product in data_products:\n",
    "    if (data_product['dataProductCode'] == PRODUCTCODE):\n",
    "        months = data_product['availableMonths']\n",
    "\n",
    "print(months)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the result we select the date range for only these lidar data:"
   ]
  },

    }
   ],
   "source": [
    "data_response = requests.get(SERVER + 'data/' + PRODUCTCODE + '/' + SITECODE + '/' + '2017-08')\n",
    "data_response_json = data_response.json()\n",
    "print(json.dumps(data_response_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how many files are in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of files in dataset: \n",
      "444\n"
     ]
    }
   ],
   "source": [
    "print(\"number of files in dataset: \")\n",
    "number_files = print(len(data_response_json[\"data\"][\"files\"][0][\"url\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The JSON blob returns with the name of the tiles and their url for downloading.\n",
    "\n",
    "We can go a level deeper into the JSON by looking for the individual file url, name, and size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"https://neon-aop-product.s3.data.neonscience.org:443/2017/FullSite/D14/2017_SRER_1/L1/DiscreteLidar/ClassifiedPointCloud/NEON_D14_SRER_DP1_509000_3528000_classified_point_cloud.laz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20180119T212520Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=pub-internal-read%2F20180119%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=b7c6ad8673032cf7d449227cc2eed193e72c383c8394f9fcdb14da0eb92f03cc\"\n",
      "\"NEON_D14_SRER_DP1_509000_3528000_classified_point_cloud.laz\"\n",
      "\"9576468\"\n"
     ]
    }
   ],
   "source": [
    "data_url = data_response_json[\"data\"][\"files\"][0][\"url\"]\n",
    "data_name = data_response_json[\"data\"][\"files\"][0][\"name\"]\n",
    "data_size = data_response_json[\"data\"][\"files\"][0][\"size\"]\n",
    "print(json.dumps(data_url, indent=0))\n",
    "print(json.dumps(data_name, indent=0))\n",
    "print(json.dumps(data_size, indent=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://neon-aop-product.s3.data.neonscience.org:443/2017/FullSite/D14/2017_SRER_1/L1/DiscreteLidar/ClassifiedPointCloud/NEON_D14_SRER_DP1_509000_3528000_classified_point_cloud.laz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20180119T212520Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=pub-internal-read%2F20180119%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=b7c6ad8673032cf7d449227cc2eed193e72c383c8394f9fcdb14da0eb92f03cc\n"
     ]
    }
   ],
   "source": [
    "print(data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/vol_c/srer/NEON_D14_SRER_DP1_509000_3528000_classified_point_cloud.laz\n"
     ]
    }
   ],
   "source": [
    "path = '/vol_c/srer/' + data_name\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data URL: https://neon-aop-product.s3.data.neonscience.org:443/2017/FullSite/D14/2017_SRER_1/L1/DiscreteLidar/ClassifiedPointCloud/NEON_D14_SRER_DP1_509000_3528000_classified_point_cloud.laz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20180119T212526Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=pub-internal-read%2F20180119%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=f26ab1a78e05f9bf35752fb65d892d2f2751c9664e55bea8b557d831f2eae5d0\n"
     ]
    }
   ],
   "source": [
    "data_response = requests.get(SERVER + 'data/' + PRODUCTCODE + '/' + SITECODE + '/' + '2017-08')\n",
    "data_response_json = data_response.json()\n",
    "data_url = data_response_json[\"data\"][\"files\"][0][\"url\"] \n",
    "print(\"Data URL: \" + data_url)\n",
    "data_name = data_response_json[\"data\"][\"files\"][0][\"name\"]\n",
    "data_size = data_response_json[\"data\"][\"files\"][0][\"size\"]\n",
    "path = '/vol_c/srer/' + data_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEON_D14_SRER_DP1_509000_3528000_classified_point_cloud.laz\n"
     ]
    }
   ],
   "source": [
    "extension_filename = data_url.split('/')[-1]\n",
    "local_filename = extension_filename.split('?')[-2]\n",
    "print(local_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to download individual files using the GET command: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file of size 9576468 to /vol_c/srer/NEON_D14_SRER_DP1_509000_3528000_classified_point_cloud.laz\n",
      "Downloaded size: 9.1 MB\n",
      "Expected file size: 9576468 bytes\n",
      "Downloaded file size: 9.1 MB\n",
      "--- 14.98231315612793 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"Downloading file of size \" + data_size + \" to \" + path)\n",
    "response = requests.get(data_url, stream=True)  \n",
    "handle = open(path, \"wb\")\n",
    "start_time = time.time()\n",
    "for chunk in response.iter_content(chunk_size=67108864):\n",
    "    if chunk: # filter out to keep alive new chunks\n",
    "        handle.write(chunk)\n",
    "        print(\"Downloaded size: \" + file_size(path))\n",
    "    print(\"Expected file size: \" + data_size + \" bytes\")\n",
    "    print(\"Downloaded file size: \" + file_size(path))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've written a for loop to query the server for the JSON every time a new file is requested.\n",
    "\n",
    "Initially,  I had a problem with the loop timing out from the initial requests.get  because\n",
    "\n",
    "the NEON API creates a time stamp for when you hit the service, after about 5 minutes the files \n",
    "\n",
    "were breaking and only the headers were being downloaded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data URL: https://neon-aop-product.s3.data.neonscience.org:443/2017/FullSite/D14/2017_SRER_1/L1/DiscreteLidar/ClassifiedPointCloud/NEON_D14_SRER_DP1_515000_3525000_classified_point_cloud.laz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20180116T182703Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=pub-internal-read%2F20180116%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=87f69c22996a2c463ee1430339e8ae132470809a1c51ee86534d3f9712410bd1\n",
      "Downloading file of size 10600743 to /vol_c/srer/NEON_D14_SRER_DP1_515000_3525000_classified_point_cloud.laz\n",
      "NEON_D14_SRER_DP1_515000_3525000_classified_point_cloud.laz downloaded!\n",
      "Expected file size: 10600743\n",
      "Downloaded file size: 10.1 MB\n",
      "Data URL: https://neon-aop-product.s3.data.neonscience.org:443/2017/FullSite/D14/2017_SRER_1/L1/DiscreteLidar/Laz/NEON_D14_SRER_DP1_L065-1_2017082516_unclassified_point_cloud.laz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20180116T182723Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=pub-internal-read%2F20180116%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=bbfa33a5510636ff1512d52a8fc55fe5714e971cf98957c68e5c8112bcd62844\n",
      "Downloading file of size 9543780 to /vol_c/srer/NEON_D14_SRER_DP1_L065-1_2017082516_unclassified_point_cloud.laz\n",
      "NEON_D14_SRER_DP1_L065-1_2017082516_unclassified_point_cloud.laz downloaded!\n",
      "Expected file size: 9543780\n",
      "Downloaded file size: 9.1 MB\n"
     ]
    }
   ],
   "source": [
    "for x in range(0, 443):\n",
    "    data_response = requests.get(SERVER + 'data/' + PRODUCTCODE + '/' + SITECODE + '/' + '2017-08')\n",
    "    data_response_json = data_response.json()\n",
    "    data_url = data_response_json[\"data\"][\"files\"][x][\"url\"] \n",
    "    print(\"Data URL: \" + data_url)\n",
    "    data_name = data_response_json[\"data\"][\"files\"][x][\"name\"]\n",
    "    data_size = data_response_json[\"data\"][\"files\"][x][\"size\"]\n",
    "    path = '/vol_c/srer/' + data_name\n",
    "    print(\"Downloading file of size \" + data_size + \" to \" + path)\n",
    "    response = requests.get(data_url)  \n",
    "    handle = open(path, \"wb\")\n",
    "    for chunk in response.iter_content(chunk_size=67108864):\n",
    "        if chunk: # filter out to keep alive new chunks\n",
    "            handle.write(chunk)\n",
    "    print(data_name + \" downloaded!\")\n",
    "    print(\"Expected file size: \" + data_size)\n",
    "    print(\"Downloaded file size: \" + file_size(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data are done downloading to my VM, I'm ready  to move onto the next step, filtering and processing the data with PDAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
